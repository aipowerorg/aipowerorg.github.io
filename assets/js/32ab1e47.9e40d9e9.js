"use strict";(self.webpackChunkhelp=self.webpackChunkhelp||[]).push([[7056],{6843:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>g,contentTitle:()=>x,default:()=>v,frontMatter:()=>p,metadata:()=>t,toc:()=>j});const t=JSON.parse('{"id":"Chat/voice-features","title":"Voice Agents","description":"AIP brings your chatbot to life with two distinct voice functionalities: the new Realtime Voice Agent for live, spoken conversations, and the classic Voice Input/Playback for transcribing user speech and reading bot responses aloud.","source":"@site/docs/Chat/voice-features.md","sourceDirName":"Chat","slug":"/voice-features","permalink":"/docs/voice-features","draft":false,"unlisted":false,"editUrl":"https://github.com/aipowerorg/aipowerorg.github.io/edit/main/docs/Chat/voice-features.md","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"id":"voice-features","slug":"/voice-features","title":"Voice Agents","sidebar_position":6},"sidebar":"tutorialSidebar","previous":{"title":"Image","permalink":"/docs/image-features"},"next":{"title":"Security & Privacy","permalink":"/docs/security-privacy"}}');var s=i(4848),o=i(8453);const r=i.p+"assets/images/realtime-voice-addon-ad346caad30c56ee55d3bac6761b8c73.png",a=i.p+"assets/images/realtime-voice-settings-09630ef7473525e4714def9d1ccd17de.png",c=i.p+"assets/images/realtime-voice-button-7e7e0a01f07b564966b9486254895027.png",l=i.p+"assets/images/voice-input-enable-76a8a711bbf08a5474a697e3a953535d.png",d=i.p+"assets/images/voice-playback-addon-39b070f89d6febf8cf941ff39b28b094.png",h=i.p+"assets/images/elevenlabs-settings-9af135bc80a244edea04b9015edaef55.png",u=i.p+"assets/images/tts-enable-6aebeebd32168ea1822eba358b1543cc.png",p={id:"voice-features",slug:"/voice-features",title:"Voice Agents",sidebar_position:6},x="Voice Features",g={},j=[{value:"Realtime Voice Agent",id:"realtime-voice-agent",level:2},{value:"How to Enable",id:"how-to-enable",level:3},{value:"Configuration",id:"configuration",level:3},{value:"How It Works",id:"how-it-works",level:3},{value:"Standard Mode",id:"standard-mode",level:4},{value:"Direct Voice Mode (Popup Only)",id:"direct-voice-mode-popup-only",level:4},{value:"Classic Voice Features",id:"classic-voice-features",level:2},{value:"Voice Input (Speech-to-Text)",id:"voice-input-speech-to-text",level:3},{value:"How to Enable",id:"how-to-enable-1",level:4},{value:"Voice Playback (Text-to-Speech)",id:"voice-playback-text-to-speech",level:3},{value:"How to Enable",id:"how-to-enable-2",level:4},{value:"Configuration",id:"configuration-1",level:4}];function b(e){const n={admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"voice-features",children:"Voice Features"})}),"\n",(0,s.jsxs)(n.p,{children:["AIP brings your chatbot to life with two distinct voice functionalities: the new ",(0,s.jsx)(n.strong,{children:"Realtime Voice Agent"})," for live, spoken conversations, and the classic ",(0,s.jsx)(n.strong,{children:"Voice Input/Playback"})," for transcribing user speech and reading bot responses aloud."]}),"\n",(0,s.jsx)(n.h2,{id:"realtime-voice-agent",children:"Realtime Voice Agent"}),"\n",(0,s.jsx)(n.p,{children:"This feature enables low-latency, speech-to-speech conversational experiences using OpenAI's Realtime API. When activated, users can talk to your chatbot and receive spoken replies in near real-time, creating a fluid and natural voice agent."}),"\n",(0,s.jsxs)(n.admonition,{title:"This is a Pro Feature",type:"info",children:[(0,s.jsxs)(n.p,{children:["To use this feature, you need a Pro plan and the ",(0,s.jsx)(n.strong,{children:"Realtime Voice"})," addon must be enabled from the ",(0,s.jsx)(n.strong,{children:"AIP > Add-ons"})," page."]}),(0,s.jsx)("img",{src:r})]}),"\n",(0,s.jsx)(n.admonition,{type:"info",children:(0,s.jsxs)(n.p,{children:["This feature only works with OpenAI's Realtime models (",(0,s.jsx)(n.code,{children:"gpt-4o-realtime-preview"})," and ",(0,s.jsx)(n.code,{children:"gpt-4o-mini-realtime"}),"). Ensure your OpenAI API key is configured in the main dashboard."]})}),"\n",(0,s.jsx)(n.h3,{id:"how-to-enable",children:"How to Enable"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["Navigate to your chatbot's settings in ",(0,s.jsx)(n.strong,{children:"AIP > Chat"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["Open the ",(0,s.jsx)(n.strong,{children:"Voice Agent"})," accordion and check the ",(0,s.jsx)(n.strong,{children:"Enable Realtime Voice Agent"})," box."]}),"\n"]}),"\n",(0,s.jsx)("img",{src:a}),"\n",(0,s.jsx)(n.h3,{id:"configuration",children:"Configuration"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Realtime Model"}),": Choose between ",(0,s.jsx)(n.code,{children:"gpt-4o-realtime-preview"})," or the mini version."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Voice"}),": Select the OpenAI voice you want the agent to use (e.g., Alloy, Shimmer)."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Turn Detection"}),":","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"None (Push-to-Talk)"}),": The user must click the button to start and stop speaking."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Server VAD"}),": OpenAI's server detects when the user stops speaking based on silence."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Semantic VAD"}),": A more advanced detection that understands the context of the speech to determine when a turn is complete."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Response Speed"}),": Control how quickly the AI speaks, from ",(0,s.jsx)(n.code,{children:"0.25"})," (slowest) to ",(0,s.jsx)(n.code,{children:"1.5"})," (fastest)."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Enable Direct Voice Mode"}),": This transforms the popup trigger button into the main controller for the voice session. It requires ",(0,s.jsx)(n.strong,{children:"Popup Enabled"})," (in the Appearance accordion) to be active."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Advanced Settings"}),": Configure technical details like audio formats and noise reduction. The defaults are recommended for most use cases."]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"how-it-works",children:"How It Works"}),"\n",(0,s.jsx)(n.p,{children:'The Realtime Voice Agent has two modes of operation, depending on whether "Direct Voice Mode" is enabled.'}),"\n",(0,s.jsx)(n.h4,{id:"standard-mode",children:"Standard Mode"}),"\n",(0,s.jsx)(n.p,{children:"In this mode, the voice session is initiated from within the chat window."}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"The user clicks the popup icon to open the chat window."}),"\n",(0,s.jsx)(n.li,{children:"Inside the window, a new voice button appears in the input area."}),"\n",(0,s.jsx)(n.li,{children:'The user clicks this internal voice button to start the session. The button will indicate it\'s "Connecting...".'}),"\n",(0,s.jsx)(n.li,{children:'Once connected, the button changes to a "Listening" state, and the conversation begins.'}),"\n"]}),"\n",(0,s.jsx)("img",{src:c}),"\n",(0,s.jsx)(n.h4,{id:"direct-voice-mode-popup-only",children:"Direct Voice Mode (Popup Only)"}),"\n",(0,s.jsxs)(n.p,{children:["For a truly voice-first experience, you can enable ",(0,s.jsx)(n.strong,{children:"Direct Voice Mode"}),". This is ideal for scenarios where you want to offer an immediate voice assistant without requiring the user to interact with the text chat first."]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"The user clicks the main popup icon on your website."}),"\n",(0,s.jsxs)(n.li,{children:["The voice session starts ",(0,s.jsx)(n.strong,{children:"immediately"}),". The chat window does not open."]}),"\n",(0,s.jsx)(n.li,{children:"The popup icon itself animates to show the status (Connecting, Listening, Speaking)."}),"\n",(0,s.jsx)(n.li,{children:"The user talks directly to the agent, and the conversation happens entirely through voice."}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"classic-voice-features",children:"Classic Voice Features"}),"\n",(0,s.jsx)(n.p,{children:"These features add basic voice functionality to the standard text-based chat experience."}),"\n",(0,s.jsx)(n.h3,{id:"voice-input-speech-to-text",children:"Voice Input (Speech-to-Text)"}),"\n",(0,s.jsx)(n.p,{children:"This feature adds a microphone icon to the chat input field, allowing users to speak their messages, which are then transcribed into text and sent."}),"\n",(0,s.jsx)(n.admonition,{type:"info",children:(0,s.jsxs)(n.p,{children:["This feature uses ",(0,s.jsx)(n.strong,{children:"OpenAI's Whisper model"})," for transcription. Ensure your OpenAI API key is configured in the main dashboard."]})}),"\n",(0,s.jsx)(n.h4,{id:"how-to-enable-1",children:"How to Enable"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["Navigate to your chatbot's settings in ",(0,s.jsx)(n.strong,{children:"AIP > Chat"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["Open the ",(0,s.jsx)(n.strong,{children:"General"})," accordion."]}),"\n",(0,s.jsx)(n.li,{children:"Click the microphone icon next to the model selector to enable voice input for the chatbot."}),"\n"]}),"\n",(0,s.jsx)("img",{src:l}),"\n",(0,s.jsx)(n.h3,{id:"voice-playback-text-to-speech",children:"Voice Playback (Text-to-Speech)"}),"\n",(0,s.jsxs)(n.admonition,{type:"info",children:[(0,s.jsxs)(n.p,{children:["AIP supports three TTS providers: ",(0,s.jsx)(n.strong,{children:"OpenAI"}),", ",(0,s.jsx)(n.strong,{children:"Google"}),", and ",(0,s.jsx)(n.strong,{children:"ElevenLabs"}),"."]}),(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["For ",(0,s.jsx)(n.strong,{children:"OpenAI"})," and ",(0,s.jsx)(n.strong,{children:"Google"}),", the plugin uses the API keys you entered under ",(0,s.jsx)(n.strong,{children:"Main Dashboard > Providers"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["For ",(0,s.jsx)(n.strong,{children:"ElevenLabs"}),", once the ",(0,s.jsx)(n.strong,{children:"Voice Playback (TTS)"})," add-on is activated, go to ",(0,s.jsx)(n.strong,{children:"Main Dashboard > Integrations"})," to enter your ElevenLabs API key and sync available models and voices."]}),"\n"]}),(0,s.jsx)("img",{src:h,width:"600"})]}),"\n",(0,s.jsx)(n.p,{children:'This feature adds a "play" button to each of the chatbot\'s responses, allowing users to listen to the message.'}),"\n",(0,s.jsx)(n.h4,{id:"how-to-enable-2",children:"How to Enable"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["Go to ",(0,s.jsx)(n.strong,{children:"AIP > Add-ons"})," and activate the ",(0,s.jsx)(n.strong,{children:"Voice Playback (TTS)"})," add-on. This is a free add-on."]}),"\n"]}),"\n",(0,s.jsx)("img",{src:d,width:"600"}),"\n",(0,s.jsxs)(n.ol,{start:"2",children:["\n",(0,s.jsxs)(n.li,{children:["Return to your chatbot's settings in ",(0,s.jsx)(n.strong,{children:"AIP > Chat"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["Open the ",(0,s.jsx)(n.strong,{children:"Voice Playback"})," accordion and check the ",(0,s.jsx)(n.strong,{children:"Enable Voice Playback"})," box."]}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"configuration-1",children:"Configuration"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"TTS Provider"}),": Choose the service to generate the audio. Options include Google, OpenAI, and ElevenLabs."]}),"\n"]}),"\n",(0,s.jsx)("img",{src:u,width:"600"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Voice"}),": Select a specific voice.","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["For ",(0,s.jsx)(n.strong,{children:"Google"})," and ",(0,s.jsx)(n.strong,{children:"ElevenLabs"}),", you can click the ",(0,s.jsx)(n.strong,{children:"Sync"})," button to fetch the voices available in your account."]}),"\n",(0,s.jsxs)(n.li,{children:["For ",(0,s.jsx)(n.strong,{children:"OpenAI"}),", a list of standard voices is available."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Auto Play"}),": Check this box if you want the chatbot's responses to be read aloud automatically as soon as they are generated."]}),"\n"]}),"\n",(0,s.jsx)(n.admonition,{type:"note",children:(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Auto Play is not compatible with Stream Mode."})," If streaming is enabled, the voice will not play automatically."]})})]})}function v(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(b,{...e})}):b(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>a});var t=i(6540);const s={},o=t.createContext(s);function r(e){const n=t.useContext(o);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),t.createElement(o.Provider,{value:n},e.children)}}}]);